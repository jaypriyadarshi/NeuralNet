(Iteration 1 / 15280) loss: 2.307269
(Epoch 0 / 40) train acc: 0.107000; val_acc: 0.134000
(Iteration 21 / 15280) loss: 1.877175
(Iteration 41 / 15280) loss: 1.534915
(Iteration 61 / 15280) loss: 1.648078
(Iteration 81 / 15280) loss: 1.398025
(Iteration 101 / 15280) loss: 1.526429
(Iteration 121 / 15280) loss: 1.391967
(Iteration 141 / 15280) loss: 1.543784
(Iteration 161 / 15280) loss: 1.435533
(Iteration 181 / 15280) loss: 1.486310
(Iteration 201 / 15280) loss: 1.548478
(Iteration 221 / 15280) loss: 1.410939
(Iteration 241 / 15280) loss: 1.318875
(Iteration 261 / 15280) loss: 1.419916
(Iteration 281 / 15280) loss: 1.334237
(Iteration 301 / 15280) loss: 1.546394
(Iteration 321 / 15280) loss: 1.371851
(Iteration 341 / 15280) loss: 1.346714
(Iteration 361 / 15280) loss: 1.314620
(Iteration 381 / 15280) loss: 1.327115
(Epoch 1 / 40) train acc: 0.658000; val_acc: 0.683000
(Iteration 401 / 15280) loss: 1.359321
(Iteration 421 / 15280) loss: 1.275573
(Iteration 441 / 15280) loss: 1.169133
(Iteration 461 / 15280) loss: 1.187626
(Iteration 481 / 15280) loss: 1.315456
(Iteration 501 / 15280) loss: 1.248469
(Iteration 521 / 15280) loss: 1.225723
(Iteration 541 / 15280) loss: 1.348815
(Iteration 561 / 15280) loss: 1.256830
(Iteration 581 / 15280) loss: 1.197403
(Iteration 601 / 15280) loss: 1.305927
(Iteration 621 / 15280) loss: 1.144916
(Iteration 641 / 15280) loss: 1.081635
(Iteration 661 / 15280) loss: 1.426485
(Iteration 681 / 15280) loss: 1.212588
(Iteration 701 / 15280) loss: 1.364402
(Iteration 721 / 15280) loss: 1.354177
(Iteration 741 / 15280) loss: 1.188737
(Iteration 761 / 15280) loss: 1.245125
(Epoch 2 / 40) train acc: 0.707000; val_acc: 0.719000
(Iteration 781 / 15280) loss: 1.376146
(Iteration 801 / 15280) loss: 1.175222
(Iteration 821 / 15280) loss: 1.277399
(Iteration 841 / 15280) loss: 1.338028
(Iteration 861 / 15280) loss: 1.416282
(Iteration 881 / 15280) loss: 1.361539
(Iteration 901 / 15280) loss: 1.162089
(Iteration 921 / 15280) loss: 1.266969
(Iteration 941 / 15280) loss: 1.181972
(Iteration 961 / 15280) loss: 1.149653
(Iteration 981 / 15280) loss: 1.152909
(Iteration 1001 / 15280) loss: 1.065984
(Iteration 1021 / 15280) loss: 1.287956
(Iteration 1041 / 15280) loss: 1.226538
(Iteration 1061 / 15280) loss: 1.157001
(Iteration 1081 / 15280) loss: 1.232241
(Iteration 1101 / 15280) loss: 1.205544
(Iteration 1121 / 15280) loss: 1.241743
(Iteration 1141 / 15280) loss: 1.261998
^[[24~(Epoch 3 / 40) train acc: 0.785000; val_acc: 0.735000
(Iteration 1161 / 15280) loss: 1.282596
(Iteration 1181 / 15280) loss: 1.183713
(Iteration 1201 / 15280) loss: 1.256317
(Iteration 1221 / 15280) loss: 1.290001
(Iteration 1241 / 15280) loss: 1.199444
(Iteration 1261 / 15280) loss: 1.216694
(Iteration 1281 / 15280) loss: 1.295678
(Iteration 1301 / 15280) loss: 1.257384
(Iteration 1321 / 15280) loss: 1.397246
(Iteration 1341 / 15280) loss: 1.306559
(Iteration 1361 / 15280) loss: 1.310882
(Iteration 1381 / 15280) loss: 1.134212
(Iteration 1401 / 15280) loss: 1.255538
(Iteration 1421 / 15280) loss: 1.233395
(Iteration 1441 / 15280) loss: 1.338223
(Iteration 1461 / 15280) loss: 1.276985
(Iteration 1481 / 15280) loss: 1.285458
(Iteration 1501 / 15280) loss: 1.185155
(Iteration 1521 / 15280) loss: 1.306174
(Epoch 4 / 40) train acc: 0.800000; val_acc: 0.771000
(Iteration 1541 / 15280) loss: 1.190947
(Iteration 1561 / 15280) loss: 1.271211
(Iteration 1581 / 15280) loss: 1.347392
(Iteration 1601 / 15280) loss: 1.232780
(Iteration 1621 / 15280) loss: 1.248335
(Iteration 1641 / 15280) loss: 1.190819
(Iteration 1661 / 15280) loss: 1.188613
(Iteration 1681 / 15280) loss: 1.109153
(Iteration 1701 / 15280) loss: 1.251976
(Iteration 1721 / 15280) loss: 1.245883
(Iteration 1741 / 15280) loss: 1.271132
(Iteration 1761 / 15280) loss: 1.269154
(Iteration 1781 / 15280) loss: 1.373044
(Iteration 1801 / 15280) loss: 1.008123
(Iteration 1821 / 15280) loss: 1.335010
(Iteration 1841 / 15280) loss: 1.158542
(Iteration 1861 / 15280) loss: 1.081090
(Iteration 1881 / 15280) loss: 1.117963
(Iteration 1901 / 15280) loss: 1.228400
(Epoch 5 / 40) train acc: 0.822000; val_acc: 0.771000
(Iteration 1921 / 15280) loss: 1.529833
(Iteration 1941 / 15280) loss: 1.122153
(Iteration 1961 / 15280) loss: 1.080235
(Iteration 1981 / 15280) loss: 1.238660
(Iteration 2001 / 15280) loss: 1.382935
(Iteration 2021 / 15280) loss: 1.373202
(Iteration 2041 / 15280) loss: 1.282564
(Iteration 2061 / 15280) loss: 1.359144
(Iteration 2081 / 15280) loss: 1.302442
(Iteration 2101 / 15280) loss: 1.243973
(Iteration 2121 / 15280) loss: 1.199993
(Iteration 2141 / 15280) loss: 1.377796
(Iteration 2161 / 15280) loss: 1.096961
(Iteration 2181 / 15280) loss: 1.162583
(Iteration 2201 / 15280) loss: 1.428132
(Iteration 2221 / 15280) loss: 1.185193
(Iteration 2241 / 15280) loss: 1.353302
(Iteration 2261 / 15280) loss: 1.266689
(Iteration 2281 / 15280) loss: 1.253234
(Epoch 6 / 40) train acc: 0.855000; val_acc: 0.776000
(Iteration 2301 / 15280) loss: 1.139596
(Iteration 2321 / 15280) loss: 1.310545
(Iteration 2341 / 15280) loss: 1.328143
(Iteration 2361 / 15280) loss: 1.211077
(Iteration 2381 / 15280) loss: 1.199689
(Iteration 2401 / 15280) loss: 1.239860
(Iteration 2421 / 15280) loss: 1.197665
(Iteration 2441 / 15280) loss: 1.106561
(Iteration 2461 / 15280) loss: 1.389493
(Iteration 2481 / 15280) loss: 1.116875
(Iteration 2501 / 15280) loss: 1.126759
(Iteration 2521 / 15280) loss: 1.272298
(Iteration 2541 / 15280) loss: 1.234903
(Iteration 2561 / 15280) loss: 1.321536
(Iteration 2581 / 15280) loss: 1.145875
(Iteration 2601 / 15280) loss: 1.159861
(Iteration 2621 / 15280) loss: 1.248929
(Iteration 2641 / 15280) loss: 1.160726
(Iteration 2661 / 15280) loss: 1.147737
(Epoch 7 / 40) train acc: 0.848000; val_acc: 0.799000
(Iteration 2681 / 15280) loss: 1.348167
(Iteration 2701 / 15280) loss: 1.183914
(Iteration 2721 / 15280) loss: 1.197732
(Iteration 2741 / 15280) loss: 1.266780
(Iteration 2761 / 15280) loss: 1.426117
(Iteration 2781 / 15280) loss: 1.144954
(Iteration 2801 / 15280) loss: 1.397696
(Iteration 2821 / 15280) loss: 1.187844
(Iteration 2841 / 15280) loss: 1.260132
(Iteration 2861 / 15280) loss: 1.274770
(Iteration 2881 / 15280) loss: 1.159859
(Iteration 2901 / 15280) loss: 1.144116
(Iteration 2921 / 15280) loss: 1.065724
(Iteration 2941 / 15280) loss: 1.160478
(Iteration 2961 / 15280) loss: 1.308127
(Iteration 2981 / 15280) loss: 1.365250
(Iteration 3001 / 15280) loss: 1.392186
(Iteration 3021 / 15280) loss: 1.066097
(Iteration 3041 / 15280) loss: 1.303672
(Epoch 8 / 40) train acc: 0.859000; val_acc: 0.788000
(Iteration 3061 / 15280) loss: 1.129067
(Iteration 3081 / 15280) loss: 1.241166
(Iteration 3101 / 15280) loss: 1.156541
(Iteration 3121 / 15280) loss: 1.045230
(Iteration 3141 / 15280) loss: 1.175543
(Iteration 3161 / 15280) loss: 1.225576
(Iteration 3181 / 15280) loss: 1.176187
(Iteration 3201 / 15280) loss: 1.173272
(Iteration 3221 / 15280) loss: 1.212484
(Iteration 3241 / 15280) loss: 1.220985
(Iteration 3261 / 15280) loss: 1.214408
(Iteration 3281 / 15280) loss: 1.146694
(Iteration 3301 / 15280) loss: 1.092392
(Iteration 3321 / 15280) loss: 1.312304
(Iteration 3341 / 15280) loss: 1.153598
(Iteration 3361 / 15280) loss: 1.194220
(Iteration 3381 / 15280) loss: 1.038572
(Iteration 3401 / 15280) loss: 1.193691
(Iteration 3421 / 15280) loss: 1.221918
(Epoch 9 / 40) train acc: 0.857000; val_acc: 0.810000
(Iteration 3441 / 15280) loss: 1.179819
(Iteration 3461 / 15280) loss: 1.246696
(Iteration 3481 / 15280) loss: 1.179487
(Iteration 3501 / 15280) loss: 1.083358
(Iteration 3521 / 15280) loss: 1.079907
(Iteration 3541 / 15280) loss: 1.263199
(Iteration 3561 / 15280) loss: 1.211190
(Iteration 3581 / 15280) loss: 1.054863
(Iteration 3601 / 15280) loss: 1.358660
(Iteration 3621 / 15280) loss: 1.139204
(Iteration 3641 / 15280) loss: 1.133695
(Iteration 3661 / 15280) loss: 1.247732
(Iteration 3681 / 15280) loss: 1.264061
(Iteration 3701 / 15280) loss: 1.105972
(Iteration 3721 / 15280) loss: 1.299864
(Iteration 3741 / 15280) loss: 1.184311
(Iteration 3761 / 15280) loss: 1.145900
(Iteration 3781 / 15280) loss: 1.178928
(Iteration 3801 / 15280) loss: 1.176156
(Epoch 10 / 40) train acc: 0.873000; val_acc: 0.805000
(Iteration 3821 / 15280) loss: 1.129699
(Iteration 3841 / 15280) loss: 1.242488
(Iteration 3861 / 15280) loss: 1.315761
(Iteration 3881 / 15280) loss: 1.145866
(Iteration 3901 / 15280) loss: 1.100587
(Iteration 3921 / 15280) loss: 1.251995
(Iteration 3941 / 15280) loss: 1.123221
(Iteration 3961 / 15280) loss: 1.300314
(Iteration 3981 / 15280) loss: 1.120340
(Iteration 4001 / 15280) loss: 1.121558
(Iteration 4021 / 15280) loss: 1.194693
(Iteration 4041 / 15280) loss: 1.148541
(Iteration 4061 / 15280) loss: 1.246806
(Iteration 4081 / 15280) loss: 1.281419
(Iteration 4101 / 15280) loss: 1.023103
(Iteration 4121 / 15280) loss: 1.163947
(Iteration 4141 / 15280) loss: 1.348600
(Iteration 4161 / 15280) loss: 1.058635
(Iteration 4181 / 15280) loss: 1.129773
(Iteration 4201 / 15280) loss: 1.197422
(Epoch 11 / 40) train acc: 0.892000; val_acc: 0.802000
(Iteration 4221 / 15280) loss: 1.071470
(Iteration 4241 / 15280) loss: 1.137017
(Iteration 4261 / 15280) loss: 1.144860
(Iteration 4281 / 15280) loss: 1.161703
(Iteration 4301 / 15280) loss: 1.283271
(Iteration 4321 / 15280) loss: 1.035383
(Iteration 4341 / 15280) loss: 1.136009
(Iteration 4361 / 15280) loss: 1.264328
(Iteration 4381 / 15280) loss: 1.224605
(Iteration 4401 / 15280) loss: 1.219271
(Iteration 4421 / 15280) loss: 1.126230
(Iteration 4441 / 15280) loss: 1.248222
(Iteration 4461 / 15280) loss: 1.277545
(Iteration 4481 / 15280) loss: 1.129977
(Iteration 4501 / 15280) loss: 0.973063
(Iteration 4521 / 15280) loss: 1.128350
(Iteration 4541 / 15280) loss: 1.211982
(Iteration 4561 / 15280) loss: 1.077118
(Iteration 4581 / 15280) loss: 1.221454
(Epoch 12 / 40) train acc: 0.881000; val_acc: 0.804000
(Iteration 4601 / 15280) loss: 1.202973
(Iteration 4621 / 15280) loss: 1.354132
(Iteration 4641 / 15280) loss: 1.295907
(Iteration 4661 / 15280) loss: 1.123415
(Iteration 4681 / 15280) loss: 1.173354
(Iteration 4701 / 15280) loss: 1.361928
(Iteration 4721 / 15280) loss: 1.166929
(Iteration 4741 / 15280) loss: 1.091037
(Iteration 4761 / 15280) loss: 1.170770
(Iteration 4781 / 15280) loss: 1.190767
(Iteration 4801 / 15280) loss: 1.173740
(Iteration 4821 / 15280) loss: 1.179701
(Iteration 4841 / 15280) loss: 1.206866
(Iteration 4861 / 15280) loss: 1.294042
(Iteration 4881 / 15280) loss: 1.324945
(Iteration 4901 / 15280) loss: 1.090755
(Iteration 4921 / 15280) loss: 1.308837
(Iteration 4941 / 15280) loss: 1.142998
(Iteration 4961 / 15280) loss: 1.125891
(Epoch 13 / 40) train acc: 0.896000; val_acc: 0.818000
(Iteration 4981 / 15280) loss: 1.265938
(Iteration 5001 / 15280) loss: 1.242727
(Iteration 5021 / 15280) loss: 1.171073
(Iteration 5041 / 15280) loss: 1.002714
(Iteration 5061 / 15280) loss: 1.028685
(Iteration 5081 / 15280) loss: 1.143688
(Iteration 5101 / 15280) loss: 1.130806
(Iteration 5121 / 15280) loss: 1.218599
(Iteration 5141 / 15280) loss: 1.136228
(Iteration 5161 / 15280) loss: 1.133866
(Iteration 5181 / 15280) loss: 1.069496
(Iteration 5201 / 15280) loss: 1.198300
(Iteration 5221 / 15280) loss: 1.092867
(Iteration 5241 / 15280) loss: 1.215590
(Iteration 5261 / 15280) loss: 1.054444
(Iteration 5281 / 15280) loss: 1.197609
(Iteration 5301 / 15280) loss: 1.059039
(Iteration 5321 / 15280) loss: 1.125113
(Iteration 5341 / 15280) loss: 1.195793
(Epoch 14 / 40) train acc: 0.892000; val_acc: 0.816000
(Iteration 5361 / 15280) loss: 1.166118
(Iteration 5381 / 15280) loss: 1.323412
(Iteration 5401 / 15280) loss: 1.064405
(Iteration 5421 / 15280) loss: 1.181693
(Iteration 5441 / 15280) loss: 1.225664
(Iteration 5461 / 15280) loss: 1.090082
(Iteration 5481 / 15280) loss: 1.304346
(Iteration 5501 / 15280) loss: 1.156930
(Iteration 5521 / 15280) loss: 1.032352
(Iteration 5541 / 15280) loss: 1.170996
(Iteration 5561 / 15280) loss: 1.166086
(Iteration 5581 / 15280) loss: 1.159214
(Iteration 5601 / 15280) loss: 1.289114
(Iteration 5621 / 15280) loss: 1.020091
(Iteration 5641 / 15280) loss: 1.029803
(Iteration 5661 / 15280) loss: 1.213059
(Iteration 5681 / 15280) loss: 1.049640
(Iteration 5701 / 15280) loss: 1.097946
(Iteration 5721 / 15280) loss: 1.083642
(Epoch 15 / 40) train acc: 0.919000; val_acc: 0.825000
(Iteration 5741 / 15280) loss: 1.053974
(Iteration 5761 / 15280) loss: 1.044164
(Iteration 5781 / 15280) loss: 1.187198
(Iteration 5801 / 15280) loss: 1.052429
(Iteration 5821 / 15280) loss: 1.120698
(Iteration 5841 / 15280) loss: 1.241668
(Iteration 5861 / 15280) loss: 1.285107
(Iteration 5881 / 15280) loss: 1.155320
(Iteration 5901 / 15280) loss: 1.312288
(Iteration 5921 / 15280) loss: 1.223990
(Iteration 5941 / 15280) loss: 1.276481
(Iteration 5961 / 15280) loss: 1.211607
(Iteration 5981 / 15280) loss: 1.116445
(Iteration 6001 / 15280) loss: 1.241059
(Iteration 6021 / 15280) loss: 1.157462
(Iteration 6041 / 15280) loss: 1.183321
(Iteration 6061 / 15280) loss: 1.187609
(Iteration 6081 / 15280) loss: 1.138418
(Iteration 6101 / 15280) loss: 1.136421
(Epoch 16 / 40) train acc: 0.912000; val_acc: 0.830000
(Iteration 6121 / 15280) loss: 1.178871
(Iteration 6141 / 15280) loss: 1.123883
(Iteration 6161 / 15280) loss: 1.201136
(Iteration 6181 / 15280) loss: 1.231010
(Iteration 6201 / 15280) loss: 1.193618
(Iteration 6221 / 15280) loss: 1.232040
(Iteration 6241 / 15280) loss: 1.058743
(Iteration 6261 / 15280) loss: 1.153293
(Iteration 6281 / 15280) loss: 1.319782
(Iteration 6301 / 15280) loss: 1.159846
(Iteration 6321 / 15280) loss: 1.173376
(Iteration 6341 / 15280) loss: 1.242860
(Iteration 6361 / 15280) loss: 1.166032
(Iteration 6381 / 15280) loss: 1.056443
(Iteration 6401 / 15280) loss: 1.033931
(Iteration 6421 / 15280) loss: 1.132523
(Iteration 6441 / 15280) loss: 1.232515
(Iteration 6461 / 15280) loss: 1.083139
(Iteration 6481 / 15280) loss: 1.270320
(Epoch 17 / 40) train acc: 0.917000; val_acc: 0.811000
(Iteration 6501 / 15280) loss: 1.124726
(Iteration 6521 / 15280) loss: 1.104576
(Iteration 6541 / 15280) loss: 1.221302
(Iteration 6561 / 15280) loss: 1.074845
(Iteration 6581 / 15280) loss: 1.137615
(Iteration 6601 / 15280) loss: 1.116620
(Iteration 6621 / 15280) loss: 1.095989
(Iteration 6641 / 15280) loss: 1.093631
(Iteration 6661 / 15280) loss: 1.047848
(Iteration 6681 / 15280) loss: 1.136306
(Iteration 6701 / 15280) loss: 1.296999
(Iteration 6721 / 15280) loss: 1.215928
(Iteration 6741 / 15280) loss: 1.086010
(Iteration 6761 / 15280) loss: 1.127184
(Iteration 6781 / 15280) loss: 1.066905
(Iteration 6801 / 15280) loss: 1.064754
(Iteration 6821 / 15280) loss: 1.083241
(Iteration 6841 / 15280) loss: 1.186062
(Iteration 6861 / 15280) loss: 1.089614
(Epoch 18 / 40) train acc: 0.913000; val_acc: 0.806000
(Iteration 6881 / 15280) loss: 1.236093
(Iteration 6901 / 15280) loss: 1.139417
(Iteration 6921 / 15280) loss: 1.171633
(Iteration 6941 / 15280) loss: 1.263697
(Iteration 6961 / 15280) loss: 1.081606
(Iteration 6981 / 15280) loss: 1.162650
(Iteration 7001 / 15280) loss: 1.067556
(Iteration 7021 / 15280) loss: 1.117846
(Iteration 7041 / 15280) loss: 1.237814
(Iteration 7061 / 15280) loss: 1.148063
(Iteration 7081 / 15280) loss: 1.155995
(Iteration 7101 / 15280) loss: 1.229881
(Iteration 7121 / 15280) loss: 1.025978
(Iteration 7141 / 15280) loss: 1.108909
(Iteration 7161 / 15280) loss: 1.245674
(Iteration 7181 / 15280) loss: 1.190392
(Iteration 7201 / 15280) loss: 1.135738
(Iteration 7221 / 15280) loss: 1.081552
(Iteration 7241 / 15280) loss: 1.058948
(Epoch 19 / 40) train acc: 0.919000; val_acc: 0.824000
(Iteration 7261 / 15280) loss: 1.294899
(Iteration 7281 / 15280) loss: 1.056761
(Iteration 7301 / 15280) loss: 1.111851
(Iteration 7321 / 15280) loss: 1.050064
(Iteration 7341 / 15280) loss: 1.105308
(Iteration 7361 / 15280) loss: 1.028485
(Iteration 7381 / 15280) loss: 1.082263
(Iteration 7401 / 15280) loss: 1.139244
(Iteration 7421 / 15280) loss: 1.280940
(Iteration 7441 / 15280) loss: 1.271779
(Iteration 7461 / 15280) loss: 1.170202
(Iteration 7481 / 15280) loss: 1.033784
(Iteration 7501 / 15280) loss: 1.137011
(Iteration 7521 / 15280) loss: 1.112628
(Iteration 7541 / 15280) loss: 1.120295
(Iteration 7561 / 15280) loss: 1.175872
(Iteration 7581 / 15280) loss: 1.192936
(Iteration 7601 / 15280) loss: 1.266081
(Iteration 7621 / 15280) loss: 1.241631
(Epoch 20 / 40) train acc: 0.900000; val_acc: 0.809000
(Iteration 7641 / 15280) loss: 1.236898
(Iteration 7661 / 15280) loss: 1.298517
(Iteration 7681 / 15280) loss: 1.120732
(Iteration 7701 / 15280) loss: 1.123163
(Iteration 7721 / 15280) loss: 1.090273
(Iteration 7741 / 15280) loss: 1.210136
(Iteration 7761 / 15280) loss: 1.367498
(Iteration 7781 / 15280) loss: 1.144519
(Iteration 7801 / 15280) loss: 1.107050
(Iteration 7821 / 15280) loss: 1.170257
(Iteration 7841 / 15280) loss: 1.283196
(Iteration 7861 / 15280) loss: 1.153310
(Iteration 7881 / 15280) loss: 1.092924
(Iteration 7901 / 15280) loss: 1.076284
(Iteration 7921 / 15280) loss: 1.243140
(Iteration 7941 / 15280) loss: 1.129327
(Iteration 7961 / 15280) loss: 1.136081
(Iteration 7981 / 15280) loss: 1.044146
(Iteration 8001 / 15280) loss: 1.146986
(Iteration 8021 / 15280) loss: 1.079090
(Epoch 21 / 40) train acc: 0.913000; val_acc: 0.810000
(Iteration 8041 / 15280) loss: 1.180850
(Iteration 8061 / 15280) loss: 1.232301
(Iteration 8081 / 15280) loss: 1.258058
(Iteration 8101 / 15280) loss: 1.121259
(Iteration 8121 / 15280) loss: 1.060736
(Iteration 8141 / 15280) loss: 1.196511
(Iteration 8161 / 15280) loss: 1.154147
(Iteration 8181 / 15280) loss: 1.219452
(Iteration 8201 / 15280) loss: 1.067214
(Iteration 8221 / 15280) loss: 1.140756
(Iteration 8241 / 15280) loss: 1.127928
(Iteration 8261 / 15280) loss: 1.093425
(Iteration 8281 / 15280) loss: 1.244129
(Iteration 8301 / 15280) loss: 1.176886
(Iteration 8321 / 15280) loss: 1.205976
(Iteration 8341 / 15280) loss: 1.061185
(Iteration 8361 / 15280) loss: 1.055973
(Iteration 8381 / 15280) loss: 1.166177
(Iteration 8401 / 15280) loss: 1.113016
(Epoch 22 / 40) train acc: 0.933000; val_acc: 0.839000
(Iteration 8421 / 15280) loss: 1.140886
(Iteration 8441 / 15280) loss: 1.121577
(Iteration 8461 / 15280) loss: 1.027263
(Iteration 8481 / 15280) loss: 1.217372
(Iteration 8501 / 15280) loss: 1.145724
(Iteration 8521 / 15280) loss: 1.101582
(Iteration 8541 / 15280) loss: 1.055923
(Iteration 8561 / 15280) loss: 1.276790
(Iteration 8581 / 15280) loss: 1.117197
(Iteration 8601 / 15280) loss: 1.084173
(Iteration 8621 / 15280) loss: 1.159523
(Iteration 8641 / 15280) loss: 1.152649
(Iteration 8661 / 15280) loss: 1.166102
(Iteration 8681 / 15280) loss: 1.285061
(Iteration 8701 / 15280) loss: 1.125596
(Iteration 8721 / 15280) loss: 1.102550
(Iteration 8741 / 15280) loss: 1.302372
(Iteration 8761 / 15280) loss: 1.096808
(Iteration 8781 / 15280) loss: 1.145286
(Epoch 23 / 40) train acc: 0.935000; val_acc: 0.821000
(Iteration 8801 / 15280) loss: 1.114361
(Iteration 8821 / 15280) loss: 1.166538
(Iteration 8841 / 15280) loss: 1.071409
(Iteration 8861 / 15280) loss: 1.116686
(Iteration 8881 / 15280) loss: 1.254817
(Iteration 8901 / 15280) loss: 1.121020
(Iteration 8921 / 15280) loss: 1.058466
(Iteration 8941 / 15280) loss: 1.221794
(Iteration 8961 / 15280) loss: 1.281797
(Iteration 8981 / 15280) loss: 1.220354
(Iteration 9001 / 15280) loss: 1.103641
(Iteration 9021 / 15280) loss: 1.176785
(Iteration 9041 / 15280) loss: 1.071751
(Iteration 9061 / 15280) loss: 1.148386
(Iteration 9081 / 15280) loss: 1.179949
(Iteration 9101 / 15280) loss: 1.106502
(Iteration 9121 / 15280) loss: 1.327521
(Iteration 9141 / 15280) loss: 1.221144
(Iteration 9161 / 15280) loss: 1.013890
(Epoch 24 / 40) train acc: 0.927000; val_acc: 0.824000
(Iteration 9181 / 15280) loss: 1.100756
(Iteration 9201 / 15280) loss: 1.099084
(Iteration 9221 / 15280) loss: 1.113849
(Iteration 9241 / 15280) loss: 1.120298
(Iteration 9261 / 15280) loss: 1.085304
(Iteration 9281 / 15280) loss: 1.119412
(Iteration 9301 / 15280) loss: 1.318859
(Iteration 9321 / 15280) loss: 1.134399
(Iteration 9341 / 15280) loss: 1.102129
(Iteration 9361 / 15280) loss: 1.197048
(Iteration 9381 / 15280) loss: 1.185709
(Iteration 9401 / 15280) loss: 1.338443
(Iteration 9421 / 15280) loss: 1.120689
(Iteration 9441 / 15280) loss: 1.087836
(Iteration 9461 / 15280) loss: 1.105494
(Iteration 9481 / 15280) loss: 1.081778
(Iteration 9501 / 15280) loss: 1.093137
(Iteration 9521 / 15280) loss: 1.145733
(Iteration 9541 / 15280) loss: 1.293095
(Epoch 25 / 40) train acc: 0.898000; val_acc: 0.818000
(Iteration 9561 / 15280) loss: 1.079500
(Iteration 9581 / 15280) loss: 1.163302
(Iteration 9601 / 15280) loss: 1.079376
(Iteration 9621 / 15280) loss: 1.051777
(Iteration 9641 / 15280) loss: 1.074598
(Iteration 9661 / 15280) loss: 1.161674
(Iteration 9681 / 15280) loss: 1.279628
(Iteration 9701 / 15280) loss: 1.193318
(Iteration 9721 / 15280) loss: 1.152815
(Iteration 9741 / 15280) loss: 1.261289
(Iteration 9761 / 15280) loss: 1.229070
(Iteration 9781 / 15280) loss: 1.092391
(Iteration 9801 / 15280) loss: 1.085837
(Iteration 9821 / 15280) loss: 1.243467
(Iteration 9841 / 15280) loss: 1.149829
(Iteration 9861 / 15280) loss: 1.126593
(Iteration 9881 / 15280) loss: 1.153138
(Iteration 9901 / 15280) loss: 1.113332
(Iteration 9921 / 15280) loss: 1.072613
(Epoch 26 / 40) train acc: 0.939000; val_acc: 0.823000
(Iteration 9941 / 15280) loss: 1.305804
(Iteration 9961 / 15280) loss: 1.171838
(Iteration 9981 / 15280) loss: 1.081793
(Iteration 10001 / 15280) loss: 1.269896
(Iteration 10021 / 15280) loss: 1.129277
(Iteration 10041 / 15280) loss: 1.177021
(Iteration 10061 / 15280) loss: 1.157063
(Iteration 10081 / 15280) loss: 1.014194
(Iteration 10101 / 15280) loss: 1.044678
(Iteration 10121 / 15280) loss: 1.122902
(Iteration 10141 / 15280) loss: 1.156552
(Iteration 10161 / 15280) loss: 1.211335
(Iteration 10181 / 15280) loss: 1.173810
(Iteration 10201 / 15280) loss: 0.999683
(Iteration 10221 / 15280) loss: 1.162632
(Iteration 10241 / 15280) loss: 1.084927
(Iteration 10261 / 15280) loss: 1.132622
(Iteration 10281 / 15280) loss: 1.102638
(Iteration 10301 / 15280) loss: 1.184048
(Epoch 27 / 40) train acc: 0.936000; val_acc: 0.839000
(Iteration 10321 / 15280) loss: 1.221698
(Iteration 10341 / 15280) loss: 1.217488
(Iteration 10361 / 15280) loss: 1.115315
(Iteration 10381 / 15280) loss: 1.150980
(Iteration 10401 / 15280) loss: 1.134356
(Iteration 10421 / 15280) loss: 1.143762
(Iteration 10441 / 15280) loss: 1.246089
(Iteration 10461 / 15280) loss: 1.112977
(Iteration 10481 / 15280) loss: 1.268046
(Iteration 10501 / 15280) loss: 1.221205
(Iteration 10521 / 15280) loss: 1.118089
(Iteration 10541 / 15280) loss: 1.174132
(Iteration 10561 / 15280) loss: 1.141829
(Iteration 10581 / 15280) loss: 1.241921
(Iteration 10601 / 15280) loss: 1.300365
(Iteration 10621 / 15280) loss: 1.062408
(Iteration 10641 / 15280) loss: 1.065818
(Iteration 10661 / 15280) loss: 1.130798
(Iteration 10681 / 15280) loss: 1.145380
(Epoch 28 / 40) train acc: 0.932000; val_acc: 0.825000
(Iteration 10701 / 15280) loss: 1.070424
(Iteration 10721 / 15280) loss: 1.156593
(Iteration 10741 / 15280) loss: 1.134241
(Iteration 10761 / 15280) loss: 1.070704
(Iteration 10781 / 15280) loss: 1.119900
(Iteration 10801 / 15280) loss: 1.101178
(Iteration 10821 / 15280) loss: 1.132647
(Iteration 10841 / 15280) loss: 1.102300
(Iteration 10861 / 15280) loss: 1.139469
(Iteration 10881 / 15280) loss: 1.122466
(Iteration 10901 / 15280) loss: 1.101561
(Iteration 10921 / 15280) loss: 1.069128
(Iteration 10941 / 15280) loss: 1.061605
(Iteration 10961 / 15280) loss: 1.089651
(Iteration 10981 / 15280) loss: 1.145249
(Iteration 11001 / 15280) loss: 1.140578
(Iteration 11021 / 15280) loss: 1.045944
(Iteration 11041 / 15280) loss: 1.258708
(Iteration 11061 / 15280) loss: 1.130817
(Epoch 29 / 40) train acc: 0.927000; val_acc: 0.816000
(Iteration 11081 / 15280) loss: 1.019299
(Iteration 11101 / 15280) loss: 1.104437
(Iteration 11121 / 15280) loss: 1.116977
(Iteration 11141 / 15280) loss: 1.203848
(Iteration 11161 / 15280) loss: 1.018952
(Iteration 11181 / 15280) loss: 1.253257
(Iteration 11201 / 15280) loss: 1.214244
(Iteration 11221 / 15280) loss: 1.087073
(Iteration 11241 / 15280) loss: 1.123449
(Iteration 11261 / 15280) loss: 1.086315
(Iteration 11281 / 15280) loss: 1.022654
(Iteration 11301 / 15280) loss: 1.194783
(Iteration 11321 / 15280) loss: 1.052128
(Iteration 11341 / 15280) loss: 1.120490
(Iteration 11361 / 15280) loss: 1.167650
(Iteration 11381 / 15280) loss: 1.097682
(Iteration 11401 / 15280) loss: 1.035186
(Iteration 11421 / 15280) loss: 1.120040
(Iteration 11441 / 15280) loss: 1.173964
(Epoch 30 / 40) train acc: 0.920000; val_acc: 0.815000
(Iteration 11461 / 15280) loss: 1.065566
(Iteration 11481 / 15280) loss: 1.132784
(Iteration 11501 / 15280) loss: 1.093499
(Iteration 11521 / 15280) loss: 1.115024
(Iteration 11541 / 15280) loss: 1.140333
(Iteration 11561 / 15280) loss: 1.164787
(Iteration 11581 / 15280) loss: 1.061923
(Iteration 11601 / 15280) loss: 1.079122
(Iteration 11621 / 15280) loss: 1.212886
(Iteration 11641 / 15280) loss: 1.165630
(Iteration 11661 / 15280) loss: 1.071282
(Iteration 11681 / 15280) loss: 1.095734
(Iteration 11701 / 15280) loss: 1.239831
(Iteration 11721 / 15280) loss: 1.055387
(Iteration 11741 / 15280) loss: 1.131874
(Iteration 11761 / 15280) loss: 1.198415
(Iteration 11781 / 15280) loss: 1.006661
(Iteration 11801 / 15280) loss: 1.035303
(Iteration 11821 / 15280) loss: 1.151194
(Iteration 11841 / 15280) loss: 1.020519
(Epoch 31 / 40) train acc: 0.910000; val_acc: 0.810000
(Iteration 11861 / 15280) loss: 1.153784
(Iteration 11881 / 15280) loss: 1.078438
(Iteration 11901 / 15280) loss: 1.105627
(Iteration 11921 / 15280) loss: 1.120049
(Iteration 11941 / 15280) loss: 1.078599
(Iteration 11961 / 15280) loss: 1.054318
(Iteration 11981 / 15280) loss: 1.160393
(Iteration 12001 / 15280) loss: 1.091307
(Iteration 12021 / 15280) loss: 1.112158
(Iteration 12041 / 15280) loss: 1.144592
(Iteration 12061 / 15280) loss: 1.174343
(Iteration 12081 / 15280) loss: 1.099848
(Iteration 12101 / 15280) loss: 1.090220
(Iteration 12121 / 15280) loss: 1.190167
(Iteration 12141 / 15280) loss: 1.242514
(Iteration 12161 / 15280) loss: 1.119705
(Iteration 12181 / 15280) loss: 1.174537
(Iteration 12201 / 15280) loss: 1.227537
(Iteration 12221 / 15280) loss: 1.086885
(Epoch 32 / 40) train acc: 0.946000; val_acc: 0.820000
(Iteration 12241 / 15280) loss: 1.101757
(Iteration 12261 / 15280) loss: 1.179896
(Iteration 12281 / 15280) loss: 1.158236
(Iteration 12301 / 15280) loss: 1.188886
(Iteration 12321 / 15280) loss: 1.126921
(Iteration 12341 / 15280) loss: 0.996628
(Iteration 12361 / 15280) loss: 1.115466
(Iteration 12381 / 15280) loss: 1.121115
(Iteration 12401 / 15280) loss: 1.112554
(Iteration 12421 / 15280) loss: 1.115577
(Iteration 12441 / 15280) loss: 1.089227
(Iteration 12461 / 15280) loss: 1.114891
(Iteration 12481 / 15280) loss: 1.092012
(Iteration 12501 / 15280) loss: 1.120103
(Iteration 12521 / 15280) loss: 1.071805
(Iteration 12541 / 15280) loss: 1.164341
(Iteration 12561 / 15280) loss: 1.120036
(Iteration 12581 / 15280) loss: 1.281353
(Iteration 12601 / 15280) loss: 1.223459
(Epoch 33 / 40) train acc: 0.946000; val_acc: 0.836000
(Iteration 12621 / 15280) loss: 1.265721
(Iteration 12641 / 15280) loss: 1.056413
(Iteration 12661 / 15280) loss: 1.058528
(Iteration 12681 / 15280) loss: 1.084687
(Iteration 12701 / 15280) loss: 1.057538
(Iteration 12721 / 15280) loss: 1.090048
(Iteration 12741 / 15280) loss: 1.103890
(Iteration 12761 / 15280) loss: 1.154687
(Iteration 12781 / 15280) loss: 1.092082
(Iteration 12801 / 15280) loss: 1.051147
(Iteration 12821 / 15280) loss: 1.043558
(Iteration 12841 / 15280) loss: 1.099708
(Iteration 12861 / 15280) loss: 1.286534
(Iteration 12881 / 15280) loss: 1.096899
(Iteration 12901 / 15280) loss: 1.100033
(Iteration 12921 / 15280) loss: 1.100422
(Iteration 12941 / 15280) loss: 1.096551
(Iteration 12961 / 15280) loss: 1.093866
(Iteration 12981 / 15280) loss: 1.181827
(Epoch 34 / 40) train acc: 0.938000; val_acc: 0.831000
(Iteration 13001 / 15280) loss: 1.153697
(Iteration 13021 / 15280) loss: 1.141713
(Iteration 13041 / 15280) loss: 1.119576
(Iteration 13061 / 15280) loss: 1.130007
(Iteration 13081 / 15280) loss: 1.214012
(Iteration 13101 / 15280) loss: 1.084843
(Iteration 13121 / 15280) loss: 1.128039
(Iteration 13141 / 15280) loss: 1.098122
(Iteration 13161 / 15280) loss: 1.062901
(Iteration 13181 / 15280) loss: 1.038687
(Iteration 13201 / 15280) loss: 1.157722
(Iteration 13221 / 15280) loss: 1.142147
(Iteration 13241 / 15280) loss: 1.088710
(Iteration 13261 / 15280) loss: 1.014050
(Iteration 13281 / 15280) loss: 1.025349
(Iteration 13301 / 15280) loss: 1.169641
(Iteration 13321 / 15280) loss: 1.074439
(Iteration 13341 / 15280) loss: 1.060735
(Iteration 13361 / 15280) loss: 1.181932
(Epoch 35 / 40) train acc: 0.948000; val_acc: 0.810000
(Iteration 13381 / 15280) loss: 1.112696
(Iteration 13401 / 15280) loss: 1.064963
(Iteration 13421 / 15280) loss: 1.063343
(Iteration 13441 / 15280) loss: 1.068762
(Iteration 13461 / 15280) loss: 1.088834
(Iteration 13481 / 15280) loss: 1.061032
(Iteration 13501 / 15280) loss: 1.047614
(Iteration 13521 / 15280) loss: 1.110455
(Iteration 13541 / 15280) loss: 1.132262
(Iteration 13561 / 15280) loss: 1.045123
(Iteration 13581 / 15280) loss: 1.158492
(Iteration 13601 / 15280) loss: 1.254651
(Iteration 13621 / 15280) loss: 1.189716
(Iteration 13641 / 15280) loss: 1.133650
(Iteration 13661 / 15280) loss: 1.118244
(Iteration 13681 / 15280) loss: 0.998859
(Iteration 13701 / 15280) loss: 1.169056
(Iteration 13721 / 15280) loss: 1.021761
(Iteration 13741 / 15280) loss: 1.200025
(Epoch 36 / 40) train acc: 0.937000; val_acc: 0.829000
(Iteration 13761 / 15280) loss: 1.119170
(Iteration 13781 / 15280) loss: 1.078000
(Iteration 13801 / 15280) loss: 1.056389
(Iteration 13821 / 15280) loss: 1.094503
(Iteration 13841 / 15280) loss: 1.066389
(Iteration 13861 / 15280) loss: 1.057594
(Iteration 13881 / 15280) loss: 1.209317
(Iteration 13901 / 15280) loss: 1.046215
(Iteration 13921 / 15280) loss: 1.024070
(Iteration 13941 / 15280) loss: 1.065523
(Iteration 13961 / 15280) loss: 1.069464
(Iteration 13981 / 15280) loss: 1.148835
(Iteration 14001 / 15280) loss: 1.028088
(Iteration 14021 / 15280) loss: 1.059129
(Iteration 14041 / 15280) loss: 1.030059
(Iteration 14061 / 15280) loss: 1.029402
(Iteration 14081 / 15280) loss: 1.142770
(Iteration 14101 / 15280) loss: 1.190943
(Iteration 14121 / 15280) loss: 1.063730
(Epoch 37 / 40) train acc: 0.947000; val_acc: 0.846000
(Iteration 14141 / 15280) loss: 1.094550
(Iteration 14161 / 15280) loss: 1.049296
(Iteration 14181 / 15280) loss: 1.058329
(Iteration 14201 / 15280) loss: 1.053728
(Iteration 14221 / 15280) loss: 1.197842
(Iteration 14241 / 15280) loss: 1.050332
(Iteration 14261 / 15280) loss: 1.066186
(Iteration 14281 / 15280) loss: 0.982399
(Iteration 14301 / 15280) loss: 1.078931
(Iteration 14321 / 15280) loss: 1.085269
(Iteration 14341 / 15280) loss: 1.163249
(Iteration 14361 / 15280) loss: 1.196743
(Iteration 14381 / 15280) loss: 1.102588
(Iteration 14401 / 15280) loss: 1.246257
(Iteration 14421 / 15280) loss: 1.072459
(Iteration 14441 / 15280) loss: 1.093664
(Iteration 14461 / 15280) loss: 1.112524
(Iteration 14481 / 15280) loss: 1.100340
(Iteration 14501 / 15280) loss: 1.151984
(Epoch 38 / 40) train acc: 0.942000; val_acc: 0.833000
(Iteration 14521 / 15280) loss: 1.039548
(Iteration 14541 / 15280) loss: 0.962936
(Iteration 14561 / 15280) loss: 1.110337
(Iteration 14581 / 15280) loss: 1.132995
(Iteration 14601 / 15280) loss: 1.181656
(Iteration 14621 / 15280) loss: 1.171353
(Iteration 14641 / 15280) loss: 1.090568
(Iteration 14661 / 15280) loss: 1.065843
(Iteration 14681 / 15280) loss: 1.098347
(Iteration 14701 / 15280) loss: 1.135352
(Iteration 14721 / 15280) loss: 0.983898
(Iteration 14741 / 15280) loss: 1.076992
(Iteration 14761 / 15280) loss: 1.014834
(Iteration 14781 / 15280) loss: 1.170319
(Iteration 14801 / 15280) loss: 1.105735
(Iteration 14821 / 15280) loss: 1.109146
(Iteration 14841 / 15280) loss: 1.160083
(Iteration 14861 / 15280) loss: 1.079996
(Iteration 14881 / 15280) loss: 1.032176
(Epoch 39 / 40) train acc: 0.944000; val_acc: 0.827000
(Iteration 14901 / 15280) loss: 1.080648
(Iteration 14921 / 15280) loss: 1.079135
(Iteration 14941 / 15280) loss: 1.016628
(Iteration 14961 / 15280) loss: 1.052530
(Iteration 14981 / 15280) loss: 1.114474
(Iteration 15001 / 15280) loss: 1.003968
(Iteration 15021 / 15280) loss: 1.067298
(Iteration 15041 / 15280) loss: 1.046563
(Iteration 15061 / 15280) loss: 1.044718
(Iteration 15081 / 15280) loss: 0.997271
(Iteration 15101 / 15280) loss: 1.056685
(Iteration 15121 / 15280) loss: 1.048143
(Iteration 15141 / 15280) loss: 1.041242
(Iteration 15161 / 15280) loss: 0.966423
(Iteration 15181 / 15280) loss: 1.181339
(Iteration 15201 / 15280) loss: 1.140555
(Iteration 15221 / 15280) loss: 1.076351
(Iteration 15241 / 15280) loss: 1.113844
(Iteration 15261 / 15280) loss: 1.150639
(Epoch 40 / 40) train acc: 0.946000; val_acc: 0.813000
Validation set accuracy:  0.842
Test set accuracy:  0.83
a
