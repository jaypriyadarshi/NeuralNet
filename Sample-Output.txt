(Iteration 1 / 22920) loss: 2.308369
(Epoch 0 / 60) train acc: 0.113000; val_acc: 0.148000
(Iteration 21 / 22920) loss: 1.906316
(Iteration 41 / 22920) loss: 1.834872
(Iteration 61 / 22920) loss: 1.507292
(Iteration 81 / 22920) loss: 1.619260
(Iteration 101 / 22920) loss: 1.493934
(Iteration 121 / 22920) loss: 1.522655
(Iteration 141 / 22920) loss: 1.537234
(Iteration 161 / 22920) loss: 1.412839
(Iteration 181 / 22920) loss: 1.414411
(Iteration 201 / 22920) loss: 1.472622
(Iteration 221 / 22920) loss: 1.455187
(Iteration 241 / 22920) loss: 1.545096
(Iteration 261 / 22920) loss: 1.440142
(Iteration 281 / 22920) loss: 1.248391
(Iteration 301 / 22920) loss: 1.492625
(Iteration 321 / 22920) loss: 1.574044
(Iteration 341 / 22920) loss: 1.258015
(Iteration 361 / 22920) loss: 1.456262
(Iteration 381 / 22920) loss: 1.305409
(Epoch 1 / 60) train acc: 0.663000; val_acc: 0.671000
(Iteration 401 / 22920) loss: 1.425406
(Iteration 421 / 22920) loss: 1.190854
(Iteration 441 / 22920) loss: 1.170931
(Iteration 461 / 22920) loss: 1.164502
(Iteration 481 / 22920) loss: 1.343922
(Iteration 501 / 22920) loss: 1.401514
(Iteration 521 / 22920) loss: 1.200786
(Iteration 541 / 22920) loss: 1.307363
(Iteration 561 / 22920) loss: 1.353170
(Iteration 581 / 22920) loss: 1.427935
(Iteration 601 / 22920) loss: 1.151065
(Iteration 621 / 22920) loss: 1.434103
(Iteration 641 / 22920) loss: 1.365291
(Iteration 661 / 22920) loss: 1.273065
(Iteration 681 / 22920) loss: 1.211419
(Iteration 701 / 22920) loss: 1.265953
(Iteration 721 / 22920) loss: 1.177486
(Iteration 741 / 22920) loss: 1.245121
(Iteration 761 / 22920) loss: 1.108004
(Epoch 2 / 60) train acc: 0.737000; val_acc: 0.733000
(Iteration 781 / 22920) loss: 1.212332
(Iteration 801 / 22920) loss: 1.357927
(Iteration 821 / 22920) loss: 1.271382
(Iteration 841 / 22920) loss: 1.226316
(Iteration 861 / 22920) loss: 1.313589
(Iteration 881 / 22920) loss: 1.067283
(Iteration 901 / 22920) loss: 1.402285
(Iteration 921 / 22920) loss: 1.198256
(Iteration 941 / 22920) loss: 1.121044
(Iteration 961 / 22920) loss: 1.239036
(Iteration 981 / 22920) loss: 1.212001
(Iteration 1001 / 22920) loss: 1.296082
(Iteration 1021 / 22920) loss: 1.332595
(Iteration 1041 / 22920) loss: 1.361479
(Iteration 1061 / 22920) loss: 1.181292
(Iteration 1081 / 22920) loss: 1.429015
(Iteration 1101 / 22920) loss: 1.231181
(Iteration 1121 / 22920) loss: 1.409077
(Iteration 1141 / 22920) loss: 1.130348
(Epoch 3 / 60) train acc: 0.761000; val_acc: 0.748000
(Iteration 1161 / 22920) loss: 1.351509
(Iteration 1181 / 22920) loss: 1.329480
(Iteration 1201 / 22920) loss: 1.414805
(Iteration 1221 / 22920) loss: 1.397106
(Iteration 1241 / 22920) loss: 1.296658
(Iteration 1261 / 22920) loss: 1.124476
(Iteration 1281 / 22920) loss: 1.410080
(Iteration 1301 / 22920) loss: 1.210859
(Iteration 1321 / 22920) loss: 1.236084
(Iteration 1341 / 22920) loss: 1.374373
(Iteration 1361 / 22920) loss: 1.170046
(Iteration 1381 / 22920) loss: 1.340883
(Iteration 1401 / 22920) loss: 1.156196
(Iteration 1421 / 22920) loss: 1.276040
(Iteration 1441 / 22920) loss: 1.249217
(Iteration 1461 / 22920) loss: 1.132384
(Iteration 1481 / 22920) loss: 1.056378
(Iteration 1501 / 22920) loss: 1.122976
(Iteration 1521 / 22920) loss: 1.265456
(Epoch 4 / 60) train acc: 0.803000; val_acc: 0.757000
(Iteration 1541 / 22920) loss: 1.238499
(Iteration 1561 / 22920) loss: 1.158063
(Iteration 1581 / 22920) loss: 1.247218
(Iteration 1601 / 22920) loss: 1.204053
(Iteration 1621 / 22920) loss: 1.229766
(Iteration 1641 / 22920) loss: 1.109502
(Iteration 1661 / 22920) loss: 1.331229
(Iteration 1681 / 22920) loss: 1.226679
(Iteration 1701 / 22920) loss: 1.285231
(Iteration 1721 / 22920) loss: 1.279046
(Iteration 1741 / 22920) loss: 1.311000
(Iteration 1761 / 22920) loss: 1.142706
(Iteration 1781 / 22920) loss: 1.127571
(Iteration 1801 / 22920) loss: 1.063692
(Iteration 1821 / 22920) loss: 1.146203
(Iteration 1841 / 22920) loss: 1.332873
(Iteration 1861 / 22920) loss: 1.154112
(Iteration 1881 / 22920) loss: 1.137501
(Iteration 1901 / 22920) loss: 1.150350
(Epoch 5 / 60) train acc: 0.820000; val_acc: 0.768000
(Iteration 1921 / 22920) loss: 1.058940
(Iteration 1941 / 22920) loss: 1.179226
(Iteration 1961 / 22920) loss: 1.196136
(Iteration 1981 / 22920) loss: 1.161138
(Iteration 2001 / 22920) loss: 1.117679
(Iteration 2021 / 22920) loss: 1.190335
(Iteration 2041 / 22920) loss: 1.063544
(Iteration 2061 / 22920) loss: 1.224371
(Iteration 2081 / 22920) loss: 1.253369
(Iteration 2101 / 22920) loss: 1.229603
(Iteration 2121 / 22920) loss: 1.198516
(Iteration 2141 / 22920) loss: 1.182566
(Iteration 2161 / 22920) loss: 1.267325
(Iteration 2181 / 22920) loss: 1.153743
(Iteration 2201 / 22920) loss: 1.303220
(Iteration 2221 / 22920) loss: 1.171584
(Iteration 2241 / 22920) loss: 1.173335
(Iteration 2261 / 22920) loss: 1.278090
(Iteration 2281 / 22920) loss: 1.244840
(Epoch 6 / 60) train acc: 0.856000; val_acc: 0.784000
(Iteration 2301 / 22920) loss: 1.101118
(Iteration 2321 / 22920) loss: 1.236398
(Iteration 2341 / 22920) loss: 1.138153
(Iteration 2361 / 22920) loss: 1.123122
(Iteration 2381 / 22920) loss: 1.089118
(Iteration 2401 / 22920) loss: 1.234352
(Iteration 2421 / 22920) loss: 1.190564
(Iteration 2441 / 22920) loss: 1.138807
(Iteration 2461 / 22920) loss: 1.111700
(Iteration 2481 / 22920) loss: 1.180260
(Iteration 2501 / 22920) loss: 1.150543
(Iteration 2521 / 22920) loss: 1.206745
(Iteration 2541 / 22920) loss: 1.228707
(Iteration 2561 / 22920) loss: 1.232103
(Iteration 2581 / 22920) loss: 1.052586
(Iteration 2601 / 22920) loss: 1.130798
(Iteration 2621 / 22920) loss: 1.233196
(Iteration 2641 / 22920) loss: 1.171009
(Iteration 2661 / 22920) loss: 1.070204
(Epoch 7 / 60) train acc: 0.852000; val_acc: 0.792000
(Iteration 2681 / 22920) loss: 1.339886
(Iteration 2701 / 22920) loss: 1.205766
(Iteration 2721 / 22920) loss: 1.186191
(Iteration 2741 / 22920) loss: 1.260173
(Iteration 2761 / 22920) loss: 1.195249
(Iteration 2781 / 22920) loss: 1.151717
(Iteration 2801 / 22920) loss: 1.158267
(Iteration 2821 / 22920) loss: 1.150237
(Iteration 2841 / 22920) loss: 1.126142
(Iteration 2861 / 22920) loss: 1.114754
(Iteration 2881 / 22920) loss: 1.105418
(Iteration 2901 / 22920) loss: 1.158029
(Iteration 2921 / 22920) loss: 1.164571
(Iteration 2941 / 22920) loss: 1.283429
(Iteration 2961 / 22920) loss: 1.169150
(Iteration 2981 / 22920) loss: 1.227378
(Iteration 3001 / 22920) loss: 1.156502
(Iteration 3021 / 22920) loss: 1.213268
(Iteration 3041 / 22920) loss: 1.197980
(Epoch 8 / 60) train acc: 0.835000; val_acc: 0.796000
(Iteration 3061 / 22920) loss: 1.186179
(Iteration 3081 / 22920) loss: 1.196819
(Iteration 3101 / 22920) loss: 1.162635
(Iteration 3121 / 22920) loss: 1.164010
(Iteration 3141 / 22920) loss: 1.094217
(Iteration 3161 / 22920) loss: 1.132765
(Iteration 3181 / 22920) loss: 1.207989
(Iteration 3201 / 22920) loss: 0.953950
(Iteration 3221 / 22920) loss: 1.123273
(Iteration 3241 / 22920) loss: 1.131588
(Iteration 3261 / 22920) loss: 1.418523
(Iteration 3281 / 22920) loss: 1.244646
(Iteration 3301 / 22920) loss: 1.197345
(Iteration 3321 / 22920) loss: 1.294766
(Iteration 3341 / 22920) loss: 1.193022
(Iteration 3361 / 22920) loss: 1.099151
(Iteration 3381 / 22920) loss: 1.299176
(Iteration 3401 / 22920) loss: 1.030953
(Iteration 3421 / 22920) loss: 1.183946
(Epoch 9 / 60) train acc: 0.870000; val_acc: 0.784000
(Iteration 3441 / 22920) loss: 1.246616
(Iteration 3461 / 22920) loss: 1.323192
(Iteration 3481 / 22920) loss: 1.333246
(Iteration 3501 / 22920) loss: 1.282379
(Iteration 3521 / 22920) loss: 1.136994
(Iteration 3541 / 22920) loss: 1.320262
(Iteration 3561 / 22920) loss: 1.150843
(Iteration 3581 / 22920) loss: 1.199195
(Iteration 3601 / 22920) loss: 1.196147
(Iteration 3621 / 22920) loss: 1.062632
(Iteration 3641 / 22920) loss: 1.197572
(Iteration 3661 / 22920) loss: 1.246722
(Iteration 3681 / 22920) loss: 1.038048
(Iteration 3701 / 22920) loss: 1.067388
(Iteration 3721 / 22920) loss: 1.190367
(Iteration 3741 / 22920) loss: 1.147774
(Iteration 3761 / 22920) loss: 1.153427
(Iteration 3781 / 22920) loss: 1.075906
(Iteration 3801 / 22920) loss: 1.134390
(Epoch 10 / 60) train acc: 0.873000; val_acc: 0.805000
(Iteration 3821 / 22920) loss: 1.152899
(Iteration 3841 / 22920) loss: 1.073244
(Iteration 3861 / 22920) loss: 1.139140
(Iteration 3881 / 22920) loss: 1.204562
(Iteration 3901 / 22920) loss: 1.305018
(Iteration 3921 / 22920) loss: 1.289773
(Iteration 3941 / 22920) loss: 1.132732
(Iteration 3961 / 22920) loss: 1.156088
(Iteration 3981 / 22920) loss: 1.146655
(Iteration 4001 / 22920) loss: 1.247629
(Iteration 4021 / 22920) loss: 1.147059
(Iteration 4041 / 22920) loss: 1.151070
(Iteration 4061 / 22920) loss: 1.183990
(Iteration 4081 / 22920) loss: 1.122735
(Iteration 4101 / 22920) loss: 1.092300
(Iteration 4121 / 22920) loss: 1.218816
(Iteration 4141 / 22920) loss: 1.415336
(Iteration 4161 / 22920) loss: 1.269569
(Iteration 4181 / 22920) loss: 1.122710
(Iteration 4201 / 22920) loss: 1.205707
(Epoch 11 / 60) train acc: 0.886000; val_acc: 0.809000
(Iteration 4221 / 22920) loss: 1.236964
(Iteration 4241 / 22920) loss: 1.234097
(Iteration 4261 / 22920) loss: 1.184636
(Iteration 4281 / 22920) loss: 1.207851
(Iteration 4301 / 22920) loss: 1.208927
(Iteration 4321 / 22920) loss: 1.194946
(Iteration 4341 / 22920) loss: 1.234269
(Iteration 4361 / 22920) loss: 1.131483
(Iteration 4381 / 22920) loss: 1.241293
(Iteration 4401 / 22920) loss: 1.192142
(Iteration 4421 / 22920) loss: 1.170606
(Iteration 4441 / 22920) loss: 1.205496
(Iteration 4461 / 22920) loss: 1.171218
(Iteration 4481 / 22920) loss: 1.070657
(Iteration 4501 / 22920) loss: 1.353880
(Iteration 4521 / 22920) loss: 1.058252
(Iteration 4541 / 22920) loss: 1.241527
(Iteration 4561 / 22920) loss: 1.184873
(Iteration 4581 / 22920) loss: 1.061011
(Epoch 12 / 60) train acc: 0.872000; val_acc: 0.803000
(Iteration 4601 / 22920) loss: 1.062819
(Iteration 4621 / 22920) loss: 1.216930
(Iteration 4641 / 22920) loss: 1.203227
(Iteration 4661 / 22920) loss: 1.305102
(Iteration 4681 / 22920) loss: 1.182791
(Iteration 4701 / 22920) loss: 1.142591
(Iteration 4721 / 22920) loss: 1.136243
(Iteration 4741 / 22920) loss: 1.168786
(Iteration 4761 / 22920) loss: 1.232410
(Iteration 4781 / 22920) loss: 1.087605
(Iteration 4801 / 22920) loss: 1.249680
(Iteration 4821 / 22920) loss: 1.323749
(Iteration 4841 / 22920) loss: 1.008340
(Iteration 4861 / 22920) loss: 1.029121
(Iteration 4881 / 22920) loss: 1.144053
(Iteration 4901 / 22920) loss: 1.149935
(Iteration 4921 / 22920) loss: 1.103064
(Iteration 4941 / 22920) loss: 1.232323
(Iteration 4961 / 22920) loss: 1.103346
(Epoch 13 / 60) train acc: 0.905000; val_acc: 0.819000
(Iteration 4981 / 22920) loss: 1.146285
(Iteration 5001 / 22920) loss: 1.261665
(Iteration 5021 / 22920) loss: 1.137130
(Iteration 5041 / 22920) loss: 1.166350
(Iteration 5061 / 22920) loss: 1.153116
(Iteration 5081 / 22920) loss: 1.138228
(Iteration 5101 / 22920) loss: 1.080995
(Iteration 5121 / 22920) loss: 1.055327
(Iteration 5141 / 22920) loss: 1.190490
(Iteration 5161 / 22920) loss: 1.481094
(Iteration 5181 / 22920) loss: 1.201026
(Iteration 5201 / 22920) loss: 1.026464
(Iteration 5221 / 22920) loss: 1.389025
(Iteration 5241 / 22920) loss: 1.267965
(Iteration 5261 / 22920) loss: 1.400646
(Iteration 5281 / 22920) loss: 1.171222
(Iteration 5301 / 22920) loss: 1.194724
(Iteration 5321 / 22920) loss: 1.017937
(Iteration 5341 / 22920) loss: 1.254367
(Epoch 14 / 60) train acc: 0.904000; val_acc: 0.801000
(Iteration 5361 / 22920) loss: 1.109311
(Iteration 5381 / 22920) loss: 1.123563
(Iteration 5401 / 22920) loss: 1.140885
(Iteration 5421 / 22920) loss: 1.185789
(Iteration 5441 / 22920) loss: 1.123816
(Iteration 5461 / 22920) loss: 1.441247
(Iteration 5481 / 22920) loss: 1.211535
(Iteration 5501 / 22920) loss: 1.202362
(Iteration 5521 / 22920) loss: 1.154075
(Iteration 5541 / 22920) loss: 1.071019
(Iteration 5561 / 22920) loss: 1.148368
(Iteration 5581 / 22920) loss: 1.211614
(Iteration 5601 / 22920) loss: 1.199982
(Iteration 5621 / 22920) loss: 1.198651
(Iteration 5641 / 22920) loss: 1.123720
(Iteration 5661 / 22920) loss: 1.140081
(Iteration 5681 / 22920) loss: 1.049641
(Iteration 5701 / 22920) loss: 1.079203
(Iteration 5721 / 22920) loss: 1.103073
(Epoch 15 / 60) train acc: 0.908000; val_acc: 0.811000
(Iteration 5741 / 22920) loss: 1.093039
(Iteration 5761 / 22920) loss: 1.207913
(Iteration 5781 / 22920) loss: 1.198078
(Iteration 5801 / 22920) loss: 1.179342
(Iteration 5821 / 22920) loss: 1.238141
(Iteration 5841 / 22920) loss: 1.174060
(Iteration 5861 / 22920) loss: 1.092813
(Iteration 5881 / 22920) loss: 1.177636
(Iteration 5901 / 22920) loss: 1.254512
(Iteration 5921 / 22920) loss: 1.114494
(Iteration 5941 / 22920) loss: 1.232091
(Iteration 5961 / 22920) loss: 1.143327
(Iteration 5981 / 22920) loss: 1.232695
(Iteration 6001 / 22920) loss: 1.138664
(Iteration 6021 / 22920) loss: 1.118071
(Iteration 6041 / 22920) loss: 1.136728
(Iteration 6061 / 22920) loss: 1.112161
(Iteration 6081 / 22920) loss: 1.297799
(Iteration 6101 / 22920) loss: 1.077909
(Epoch 16 / 60) train acc: 0.920000; val_acc: 0.801000
(Iteration 6121 / 22920) loss: 1.193721
(Iteration 6141 / 22920) loss: 1.128108
(Iteration 6161 / 22920) loss: 1.134611
(Iteration 6181 / 22920) loss: 1.168259
(Iteration 6201 / 22920) loss: 1.151959
(Iteration 6221 / 22920) loss: 1.171908
(Iteration 6241 / 22920) loss: 1.090253
(Iteration 6261 / 22920) loss: 1.178362
(Iteration 6281 / 22920) loss: 1.233131
(Iteration 6301 / 22920) loss: 1.142602
(Iteration 6321 / 22920) loss: 1.003836
(Iteration 6341 / 22920) loss: 1.121095
(Iteration 6361 / 22920) loss: 1.135159
(Iteration 6381 / 22920) loss: 1.215857
(Iteration 6401 / 22920) loss: 1.281008
(Iteration 6421 / 22920) loss: 1.137509
(Iteration 6441 / 22920) loss: 1.285246
(Iteration 6461 / 22920) loss: 0.980390
(Iteration 6481 / 22920) loss: 1.273898
(Epoch 17 / 60) train acc: 0.920000; val_acc: 0.809000
(Iteration 6501 / 22920) loss: 1.224964
(Iteration 6521 / 22920) loss: 1.113434
(Iteration 6541 / 22920) loss: 1.138356
(Iteration 6561 / 22920) loss: 1.219242
(Iteration 6581 / 22920) loss: 1.176849
(Iteration 6601 / 22920) loss: 1.069382
(Iteration 6621 / 22920) loss: 1.090181
(Iteration 6641 / 22920) loss: 1.166095
(Iteration 6661 / 22920) loss: 1.131265
(Iteration 6681 / 22920) loss: 1.046011
(Iteration 6701 / 22920) loss: 1.055137
(Iteration 6721 / 22920) loss: 1.040393
(Iteration 6741 / 22920) loss: 1.199187
(Iteration 6761 / 22920) loss: 1.158779
(Iteration 6781 / 22920) loss: 1.111054
(Iteration 6801 / 22920) loss: 1.246415
(Iteration 6821 / 22920) loss: 1.113105
(Iteration 6841 / 22920) loss: 1.230906
(Iteration 6861 / 22920) loss: 1.118728
(Epoch 18 / 60) train acc: 0.908000; val_acc: 0.816000
(Iteration 6881 / 22920) loss: 1.253914
(Iteration 6901 / 22920) loss: 1.251767
(Iteration 6921 / 22920) loss: 1.138784
(Iteration 6941 / 22920) loss: 1.027839
(Iteration 6961 / 22920) loss: 1.078166
(Iteration 6981 / 22920) loss: 1.191168
(Iteration 7001 / 22920) loss: 1.312411
(Iteration 7021 / 22920) loss: 1.045727
(Iteration 7041 / 22920) loss: 1.067208
(Iteration 7061 / 22920) loss: 1.244568
(Iteration 7081 / 22920) loss: 1.165412
(Iteration 7101 / 22920) loss: 1.137365
(Iteration 7121 / 22920) loss: 1.090873
(Iteration 7141 / 22920) loss: 1.105573
(Iteration 7161 / 22920) loss: 1.112032
(Iteration 7181 / 22920) loss: 1.108702
(Iteration 7201 / 22920) loss: 1.086745
(Iteration 7221 / 22920) loss: 1.188332
(Iteration 7241 / 22920) loss: 0.994747
(Epoch 19 / 60) train acc: 0.915000; val_acc: 0.826000
(Iteration 7261 / 22920) loss: 1.107103
(Iteration 7281 / 22920) loss: 1.085377
(Iteration 7301 / 22920) loss: 1.102924
(Iteration 7321 / 22920) loss: 1.234938
(Iteration 7341 / 22920) loss: 1.285774
(Iteration 7361 / 22920) loss: 1.156546
(Iteration 7381 / 22920) loss: 1.218091
(Iteration 7401 / 22920) loss: 1.092832
(Iteration 7421 / 22920) loss: 1.092160
(Iteration 7441 / 22920) loss: 1.043810
(Iteration 7461 / 22920) loss: 1.199809
(Iteration 7481 / 22920) loss: 1.074310
(Iteration 7501 / 22920) loss: 1.236798
(Iteration 7521 / 22920) loss: 1.218338
(Iteration 7541 / 22920) loss: 1.287362
(Iteration 7561 / 22920) loss: 1.189236
(Iteration 7581 / 22920) loss: 1.334180
(Iteration 7601 / 22920) loss: 1.222407
(Iteration 7621 / 22920) loss: 1.110396
(Epoch 20 / 60) train acc: 0.909000; val_acc: 0.819000
(Iteration 7641 / 22920) loss: 1.176158
(Iteration 7661 / 22920) loss: 1.052674
(Iteration 7681 / 22920) loss: 1.160235
(Iteration 7701 / 22920) loss: 1.188183
(Iteration 7721 / 22920) loss: 1.085508
(Iteration 7741 / 22920) loss: 1.299035
(Iteration 7761 / 22920) loss: 1.203334
(Iteration 7781 / 22920) loss: 1.073352
(Iteration 7801 / 22920) loss: 1.110692
(Iteration 7821 / 22920) loss: 1.139593
(Iteration 7841 / 22920) loss: 1.274011
(Iteration 7861 / 22920) loss: 1.247520
(Iteration 7881 / 22920) loss: 1.127099
(Iteration 7901 / 22920) loss: 1.210539
(Iteration 7921 / 22920) loss: 1.178454
(Iteration 7941 / 22920) loss: 1.095011
(Iteration 7961 / 22920) loss: 1.223076
(Iteration 7981 / 22920) loss: 1.217084
(Iteration 8001 / 22920) loss: 1.229359
(Iteration 8021 / 22920) loss: 1.050287
(Epoch 21 / 60) train acc: 0.919000; val_acc: 0.808000
(Iteration 8041 / 22920) loss: 1.097578
(Iteration 8061 / 22920) loss: 1.058383
(Iteration 8081 / 22920) loss: 1.178116
(Iteration 8101 / 22920) loss: 1.124309
(Iteration 8121 / 22920) loss: 1.171506
(Iteration 8141 / 22920) loss: 1.161256
(Iteration 8161 / 22920) loss: 1.187172
(Iteration 8181 / 22920) loss: 1.165750
(Iteration 8201 / 22920) loss: 1.286394
(Iteration 8221 / 22920) loss: 1.156878
(Iteration 8241 / 22920) loss: 1.295139
(Iteration 8261 / 22920) loss: 1.142436
(Iteration 8281 / 22920) loss: 1.047343
(Iteration 8301 / 22920) loss: 1.134079
(Iteration 8321 / 22920) loss: 1.480098
(Iteration 8341 / 22920) loss: 1.184835
(Iteration 8361 / 22920) loss: 1.247257
(Iteration 8381 / 22920) loss: 1.090461
(Iteration 8401 / 22920) loss: 1.106982
(Epoch 22 / 60) train acc: 0.934000; val_acc: 0.821000
(Iteration 8421 / 22920) loss: 1.183835
(Iteration 8441 / 22920) loss: 1.148596
(Iteration 8461 / 22920) loss: 1.089127
(Iteration 8481 / 22920) loss: 1.208092
(Iteration 8501 / 22920) loss: 1.120922
(Iteration 8521 / 22920) loss: 1.214737
(Iteration 8541 / 22920) loss: 1.107272
(Iteration 8561 / 22920) loss: 1.190880
(Iteration 8581 / 22920) loss: 1.146241
(Iteration 8601 / 22920) loss: 1.125117
(Iteration 8621 / 22920) loss: 1.106506
(Iteration 8641 / 22920) loss: 1.180105
(Iteration 8661 / 22920) loss: 1.281025
(Iteration 8681 / 22920) loss: 1.277086
(Iteration 8701 / 22920) loss: 1.203882
(Iteration 8721 / 22920) loss: 1.097984
(Iteration 8741 / 22920) loss: 1.161340
(Iteration 8761 / 22920) loss: 1.106124
(Iteration 8781 / 22920) loss: 1.068858
(Epoch 23 / 60) train acc: 0.930000; val_acc: 0.807000
(Iteration 8801 / 22920) loss: 1.472543
(Iteration 8821 / 22920) loss: 1.169158
(Iteration 8841 / 22920) loss: 1.130543
(Iteration 8861 / 22920) loss: 1.061798
(Iteration 8881 / 22920) loss: 1.104743
(Iteration 8901 / 22920) loss: 1.205331
(Iteration 8921 / 22920) loss: 1.191076
(Iteration 8941 / 22920) loss: 1.128764
(Iteration 8961 / 22920) loss: 1.029498
(Iteration 8981 / 22920) loss: 0.992941
(Iteration 9001 / 22920) loss: 0.970368
(Iteration 9021 / 22920) loss: 1.237530
(Iteration 9041 / 22920) loss: 1.098154
(Iteration 9061 / 22920) loss: 1.165056
(Iteration 9081 / 22920) loss: 1.238806
(Iteration 9101 / 22920) loss: 1.261728
(Iteration 9121 / 22920) loss: 1.043076
(Iteration 9141 / 22920) loss: 1.035663
(Iteration 9161 / 22920) loss: 1.015282
(Epoch 24 / 60) train acc: 0.918000; val_acc: 0.811000
(Iteration 9181 / 22920) loss: 1.077966
(Iteration 9201 / 22920) loss: 1.143072
(Iteration 9221 / 22920) loss: 1.131387
(Iteration 9241 / 22920) loss: 1.086603
(Iteration 9261 / 22920) loss: 1.217810
(Iteration 9281 / 22920) loss: 1.212287
(Iteration 9301 / 22920) loss: 1.093214
(Iteration 9321 / 22920) loss: 0.995383
(Iteration 9341 / 22920) loss: 1.121355
(Iteration 9361 / 22920) loss: 1.064079
(Iteration 9381 / 22920) loss: 1.060264
(Iteration 9401 / 22920) loss: 1.079339
(Iteration 9421 / 22920) loss: 1.006118
(Iteration 9441 / 22920) loss: 1.166535
(Iteration 9461 / 22920) loss: 1.009411
(Iteration 9481 / 22920) loss: 1.146076
(Iteration 9501 / 22920) loss: 1.098116
(Iteration 9521 / 22920) loss: 1.243027
(Iteration 9541 / 22920) loss: 1.141587
(Epoch 25 / 60) train acc: 0.928000; val_acc: 0.804000
(Iteration 9561 / 22920) loss: 1.109471
(Iteration 9581 / 22920) loss: 1.212164
(Iteration 9601 / 22920) loss: 1.036519
(Iteration 9621 / 22920) loss: 1.087313
(Iteration 9641 / 22920) loss: 1.197904
(Iteration 9661 / 22920) loss: 0.992296
(Iteration 9681 / 22920) loss: 1.111004
(Iteration 9701 / 22920) loss: 1.051249
(Iteration 9721 / 22920) loss: 1.239493
(Iteration 9741 / 22920) loss: 1.132084
(Iteration 9761 / 22920) loss: 1.122540
(Iteration 9781 / 22920) loss: 1.319529
(Iteration 9801 / 22920) loss: 1.086668
(Iteration 9821 / 22920) loss: 1.057674
(Iteration 9841 / 22920) loss: 1.189536
(Iteration 9861 / 22920) loss: 1.203541
(Iteration 9881 / 22920) loss: 1.115236
(Iteration 9901 / 22920) loss: 1.064953
(Iteration 9921 / 22920) loss: 1.086684
(Epoch 26 / 60) train acc: 0.918000; val_acc: 0.825000
(Iteration 9941 / 22920) loss: 1.254859
(Iteration 9961 / 22920) loss: 1.144438
(Iteration 9981 / 22920) loss: 1.085111
(Iteration 10001 / 22920) loss: 1.104087
(Iteration 10021 / 22920) loss: 1.142326
(Iteration 10041 / 22920) loss: 1.243059
(Iteration 10061 / 22920) loss: 1.111720
(Iteration 10081 / 22920) loss: 1.107893
(Iteration 10101 / 22920) loss: 1.092718
(Iteration 10121 / 22920) loss: 1.073738
(Iteration 10141 / 22920) loss: 1.104730
(Iteration 10161 / 22920) loss: 1.265471
(Iteration 10181 / 22920) loss: 1.101432
(Iteration 10201 / 22920) loss: 1.201328
(Iteration 10221 / 22920) loss: 1.079944
(Iteration 10241 / 22920) loss: 1.144652
(Iteration 10261 / 22920) loss: 1.171848
(Iteration 10281 / 22920) loss: 1.061436
(Iteration 10301 / 22920) loss: 1.088566
(Epoch 27 / 60) train acc: 0.924000; val_acc: 0.807000
(Iteration 10321 / 22920) loss: 1.055100
(Iteration 10341 / 22920) loss: 0.987752
(Iteration 10361 / 22920) loss: 1.178059
(Iteration 10381 / 22920) loss: 1.088009
(Iteration 10401 / 22920) loss: 1.091621
(Iteration 10421 / 22920) loss: 1.181502
(Iteration 10441 / 22920) loss: 1.069373
(Iteration 10461 / 22920) loss: 1.092969
(Iteration 10481 / 22920) loss: 1.045810
(Iteration 10501 / 22920) loss: 1.164613
(Iteration 10521 / 22920) loss: 1.152742
(Iteration 10541 / 22920) loss: 1.093436
(Iteration 10561 / 22920) loss: 1.058277
(Iteration 10581 / 22920) loss: 1.058188
(Iteration 10601 / 22920) loss: 1.142400
(Iteration 10621 / 22920) loss: 1.155353
(Iteration 10641 / 22920) loss: 1.149660
(Iteration 10661 / 22920) loss: 1.047331
(Iteration 10681 / 22920) loss: 1.253750
(Epoch 28 / 60) train acc: 0.932000; val_acc: 0.813000
(Iteration 10701 / 22920) loss: 1.101342
(Iteration 10721 / 22920) loss: 1.112757
(Iteration 10741 / 22920) loss: 1.051334
(Iteration 10761 / 22920) loss: 1.202436
(Iteration 10781 / 22920) loss: 1.202532
(Iteration 10801 / 22920) loss: 1.048673
(Iteration 10821 / 22920) loss: 1.087472
(Iteration 10841 / 22920) loss: 1.095495
(Iteration 10861 / 22920) loss: 1.171130
(Iteration 10881 / 22920) loss: 1.229997
(Iteration 10901 / 22920) loss: 1.069943
(Iteration 10921 / 22920) loss: 1.058842
(Iteration 10941 / 22920) loss: 1.131906
(Iteration 10961 / 22920) loss: 1.128304
(Iteration 10981 / 22920) loss: 1.188186
(Iteration 11001 / 22920) loss: 1.117918
(Iteration 11021 / 22920) loss: 1.109635
(Iteration 11041 / 22920) loss: 1.305187
(Iteration 11061 / 22920) loss: 1.211989
(Epoch 29 / 60) train acc: 0.941000; val_acc: 0.818000
(Iteration 11081 / 22920) loss: 1.146962
(Iteration 11101 / 22920) loss: 1.102577
(Iteration 11121 / 22920) loss: 1.259437
(Iteration 11141 / 22920) loss: 1.155812
(Iteration 11161 / 22920) loss: 1.053973
(Iteration 11181 / 22920) loss: 1.217143
(Iteration 11201 / 22920) loss: 1.111510
(Iteration 11221 / 22920) loss: 1.046285
(Iteration 11241 / 22920) loss: 1.164597
(Iteration 11261 / 22920) loss: 1.078923
(Iteration 11281 / 22920) loss: 1.241275
(Iteration 11301 / 22920) loss: 1.178050
(Iteration 11321 / 22920) loss: 1.148918
(Iteration 11341 / 22920) loss: 1.050504
(Iteration 11361 / 22920) loss: 1.221931
(Iteration 11381 / 22920) loss: 1.247093
(Iteration 11401 / 22920) loss: 1.117021
(Iteration 11421 / 22920) loss: 1.205091
(Iteration 11441 / 22920) loss: 1.135505
(Epoch 30 / 60) train acc: 0.937000; val_acc: 0.827000
(Iteration 11461 / 22920) loss: 1.061254
(Iteration 11481 / 22920) loss: 1.076870
(Iteration 11501 / 22920) loss: 1.136514
(Iteration 11521 / 22920) loss: 1.135053
(Iteration 11541 / 22920) loss: 1.131281
(Iteration 11561 / 22920) loss: 1.097195
(Iteration 11581 / 22920) loss: 1.043050
(Iteration 11601 / 22920) loss: 1.153897
(Iteration 11621 / 22920) loss: 1.079879
(Iteration 11641 / 22920) loss: 1.043206
(Iteration 11661 / 22920) loss: 1.199188
(Iteration 11681 / 22920) loss: 1.179959
(Iteration 11701 / 22920) loss: 1.159138
(Iteration 11721 / 22920) loss: 1.088639
(Iteration 11741 / 22920) loss: 1.097888
(Iteration 11761 / 22920) loss: 1.193163
(Iteration 11781 / 22920) loss: 1.125402
(Iteration 11801 / 22920) loss: 1.065166
(Iteration 11821 / 22920) loss: 1.131737
(Iteration 11841 / 22920) loss: 1.138384
(Epoch 31 / 60) train acc: 0.946000; val_acc: 0.828000
(Iteration 11861 / 22920) loss: 1.105185
(Iteration 11881 / 22920) loss: 1.170677
(Iteration 11901 / 22920) loss: 1.092055
(Iteration 11921 / 22920) loss: 1.039102
(Iteration 11941 / 22920) loss: 1.126353
(Iteration 11961 / 22920) loss: 1.127481
(Iteration 11981 / 22920) loss: 1.069423
(Iteration 12001 / 22920) loss: 1.095804
(Iteration 12021 / 22920) loss: 1.230578
(Iteration 12041 / 22920) loss: 1.123962
(Iteration 12061 / 22920) loss: 1.107014
(Iteration 12081 / 22920) loss: 1.164628
(Iteration 12101 / 22920) loss: 1.150538
(Iteration 12121 / 22920) loss: 1.148074
(Iteration 12141 / 22920) loss: 1.072603
(Iteration 12161 / 22920) loss: 1.198016
(Iteration 12181 / 22920) loss: 1.177669
(Iteration 12201 / 22920) loss: 1.086466
(Iteration 12221 / 22920) loss: 1.193816
(Epoch 32 / 60) train acc: 0.923000; val_acc: 0.815000
(Iteration 12241 / 22920) loss: 1.221437
(Iteration 12261 / 22920) loss: 1.119496
(Iteration 12281 / 22920) loss: 1.209100
(Iteration 12301 / 22920) loss: 1.182920
(Iteration 12321 / 22920) loss: 1.279896
(Iteration 12341 / 22920) loss: 1.199720
(Iteration 12361 / 22920) loss: 1.129281
(Iteration 12381 / 22920) loss: 1.161660
(Iteration 12401 / 22920) loss: 1.107270
(Iteration 12421 / 22920) loss: 1.172604
(Iteration 12441 / 22920) loss: 1.078645
(Iteration 12461 / 22920) loss: 1.221986
(Iteration 12481 / 22920) loss: 1.090795
(Iteration 12501 / 22920) loss: 1.088837
(Iteration 12521 / 22920) loss: 1.073042
(Iteration 12541 / 22920) loss: 1.237929
(Iteration 12561 / 22920) loss: 1.098520
(Iteration 12581 / 22920) loss: 1.195851
(Iteration 12601 / 22920) loss: 1.218785
(Epoch 33 / 60) train acc: 0.937000; val_acc: 0.819000
(Iteration 12621 / 22920) loss: 1.023905
(Iteration 12641 / 22920) loss: 1.088585
(Iteration 12661 / 22920) loss: 1.222138
(Iteration 12681 / 22920) loss: 1.170965
(Iteration 12701 / 22920) loss: 1.106636
(Iteration 12721 / 22920) loss: 1.116082
(Iteration 12741 / 22920) loss: 0.999591
(Iteration 12761 / 22920) loss: 1.071784
(Iteration 12781 / 22920) loss: 1.041437
(Iteration 12801 / 22920) loss: 1.153746
(Iteration 12821 / 22920) loss: 1.190871
(Iteration 12841 / 22920) loss: 1.120023
(Iteration 12861 / 22920) loss: 1.126693
(Iteration 12881 / 22920) loss: 1.060632
(Iteration 12901 / 22920) loss: 1.202864
(Iteration 12921 / 22920) loss: 1.173564
(Iteration 12941 / 22920) loss: 1.019591
(Iteration 12961 / 22920) loss: 1.057886
(Iteration 12981 / 22920) loss: 1.098708
(Epoch 34 / 60) train acc: 0.934000; val_acc: 0.822000
(Iteration 13001 / 22920) loss: 1.262689
(Iteration 13021 / 22920) loss: 1.130052
(Iteration 13041 / 22920) loss: 1.139607
(Iteration 13061 / 22920) loss: 1.142671
(Iteration 13081 / 22920) loss: 1.135452
(Iteration 13101 / 22920) loss: 1.148959
(Iteration 13121 / 22920) loss: 1.233790
(Iteration 13141 / 22920) loss: 1.200002
(Iteration 13161 / 22920) loss: 1.085882
(Iteration 13181 / 22920) loss: 1.136439
(Iteration 13201 / 22920) loss: 1.105934
(Iteration 13221 / 22920) loss: 1.202412
(Iteration 13241 / 22920) loss: 1.220016
(Iteration 13261 / 22920) loss: 1.207430
(Iteration 13281 / 22920) loss: 1.250173
(Iteration 13301 / 22920) loss: 1.107911
(Iteration 13321 / 22920) loss: 1.166615
(Iteration 13341 / 22920) loss: 1.124399
(Iteration 13361 / 22920) loss: 1.148556
(Epoch 35 / 60) train acc: 0.931000; val_acc: 0.808000
(Iteration 13381 / 22920) loss: 1.096436
(Iteration 13401 / 22920) loss: 1.048056
(Iteration 13421 / 22920) loss: 1.121632
(Iteration 13441 / 22920) loss: 1.179022
(Iteration 13461 / 22920) loss: 1.341655
(Iteration 13481 / 22920) loss: 1.144917
(Iteration 13501 / 22920) loss: 1.117644
(Iteration 13521 / 22920) loss: 1.076431
(Iteration 13541 / 22920) loss: 1.198985
(Iteration 13561 / 22920) loss: 1.145792
(Iteration 13581 / 22920) loss: 1.100911
(Iteration 13601 / 22920) loss: 1.157144
(Iteration 13621 / 22920) loss: 1.181754
(Iteration 13641 / 22920) loss: 1.217053
(Iteration 13661 / 22920) loss: 1.249134
(Iteration 13681 / 22920) loss: 1.006388
(Iteration 13701 / 22920) loss: 1.153690
(Iteration 13721 / 22920) loss: 1.173869
(Iteration 13741 / 22920) loss: 1.184665
(Epoch 36 / 60) train acc: 0.940000; val_acc: 0.819000
(Iteration 13761 / 22920) loss: 1.149962
(Iteration 13781 / 22920) loss: 1.116266
(Iteration 13801 / 22920) loss: 1.060105
(Iteration 13821 / 22920) loss: 0.995674
(Iteration 13841 / 22920) loss: 1.028383
(Iteration 13861 / 22920) loss: 1.108933
(Iteration 13881 / 22920) loss: 1.011033
(Iteration 13901 / 22920) loss: 1.126542
(Iteration 13921 / 22920) loss: 1.059880
(Iteration 13941 / 22920) loss: 1.279085
(Iteration 13961 / 22920) loss: 1.061566
(Iteration 13981 / 22920) loss: 1.130573
(Iteration 14001 / 22920) loss: 1.131482
(Iteration 14021 / 22920) loss: 1.047820
(Iteration 14041 / 22920) loss: 1.042161
(Iteration 14061 / 22920) loss: 1.140045
(Iteration 14081 / 22920) loss: 1.173565
(Iteration 14101 / 22920) loss: 1.168331
(Iteration 14121 / 22920) loss: 1.184418
(Epoch 37 / 60) train acc: 0.941000; val_acc: 0.824000
(Iteration 14141 / 22920) loss: 1.159017
(Iteration 14161 / 22920) loss: 1.094691
(Iteration 14181 / 22920) loss: 1.176497
(Iteration 14201 / 22920) loss: 1.024346
(Iteration 14221 / 22920) loss: 1.157239
(Iteration 14241 / 22920) loss: 1.138943
(Iteration 14261 / 22920) loss: 1.148425
(Iteration 14281 / 22920) loss: 1.142669
(Iteration 14301 / 22920) loss: 1.059730
(Iteration 14321 / 22920) loss: 1.240651
(Iteration 14341 / 22920) loss: 1.145494
(Iteration 14361 / 22920) loss: 1.136117
(Iteration 14381 / 22920) loss: 1.127385
(Iteration 14401 / 22920) loss: 1.008883
(Iteration 14421 / 22920) loss: 1.004421
(Iteration 14441 / 22920) loss: 1.104716
(Iteration 14461 / 22920) loss: 1.038901
(Iteration 14481 / 22920) loss: 1.044331
(Iteration 14501 / 22920) loss: 1.157028
(Epoch 38 / 60) train acc: 0.933000; val_acc: 0.826000
(Iteration 14521 / 22920) loss: 1.081335
(Iteration 14541 / 22920) loss: 1.275623
(Iteration 14561 / 22920) loss: 0.993109
(Iteration 14581 / 22920) loss: 1.175086
(Iteration 14601 / 22920) loss: 1.101906
(Iteration 14621 / 22920) loss: 1.112831
(Iteration 14641 / 22920) loss: 1.157018
(Iteration 14661 / 22920) loss: 1.004630
(Iteration 14681 / 22920) loss: 1.116593
(Iteration 14701 / 22920) loss: 1.066761
(Iteration 14721 / 22920) loss: 0.968531
(Iteration 14741 / 22920) loss: 1.117763
(Iteration 14761 / 22920) loss: 1.111759
(Iteration 14781 / 22920) loss: 1.087741
(Iteration 14801 / 22920) loss: 0.965865
(Iteration 14821 / 22920) loss: 1.003498
(Iteration 14841 / 22920) loss: 1.120087
(Iteration 14861 / 22920) loss: 1.177301
(Iteration 14881 / 22920) loss: 1.014705
(Epoch 39 / 60) train acc: 0.941000; val_acc: 0.815000
(Iteration 14901 / 22920) loss: 1.063222
(Iteration 14921 / 22920) loss: 1.107487
(Iteration 14941 / 22920) loss: 1.057263
(Iteration 14961 / 22920) loss: 1.127075
(Iteration 14981 / 22920) loss: 1.085016
(Iteration 15001 / 22920) loss: 1.050622
(Iteration 15021 / 22920) loss: 1.142577
(Iteration 15041 / 22920) loss: 1.123968
(Iteration 15061 / 22920) loss: 0.999411
(Iteration 15081 / 22920) loss: 1.088574
(Iteration 15101 / 22920) loss: 1.093752
(Iteration 15121 / 22920) loss: 1.120325
(Iteration 15141 / 22920) loss: 1.090545
(Iteration 15161 / 22920) loss: 1.054173
(Iteration 15181 / 22920) loss: 1.207689
(Iteration 15201 / 22920) loss: 1.075088
(Iteration 15221 / 22920) loss: 1.081854
(Iteration 15241 / 22920) loss: 1.087090
(Iteration 15261 / 22920) loss: 1.077968
(Epoch 40 / 60) train acc: 0.938000; val_acc: 0.835000
